{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Logistic Regression on [MNIST](http://yann.lecun.com/exdb/mnist/) digits\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-images-idx3-ubyte.gz:  training set images (9912422 bytes)\n",
    "train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)\n",
    "t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)\n",
    "t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for confusion matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "# for loading MNIST\n",
    "from struct import unpack\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load downloaded dataset\n",
    "data_root = '../../books1000'\n",
    "def loadMNIST(imagefile, labelfile):\n",
    "    #img_filename = os.path.join(data_root, imagefile)\n",
    "    #lbl_filename = os.path.join(data_root, labelfile)\n",
    "    images = open(imagefile, 'rb')\n",
    "    labels = open(labelfile, 'rb')\n",
    "    \n",
    "    images.read(4)\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "    \n",
    "    labels.read(4)\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "    \n",
    "    x = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    y = np.zeros(N, dtype=np.uint8)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(rows*cols):\n",
    "            tmp_pixel = images.read(1)\n",
    "            tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "            x[i][j] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "        \n",
    "    images.close()\n",
    "    labels.close()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_filename = os.path.join(data_root, 'train-images-idx3-ubyte')\n",
    "train_lbl_filename = os.path.join(data_root, 'train-labels-idx1-ubyte')\n",
    "train_dataset, train_labels = loadMNIST(train_img_filename,\n",
    "                                        train_lbl_filename)\n",
    "\n",
    "test_img_filename = os.path.join(data_root, 't10k-images-idx3-ubyte')\n",
    "test_lbl_filename = os.path.join(data_root, 't10k-labels-idx1-ubyte')\n",
    "test_dataset, test_labels = loadMNIST(test_img_filename,\n",
    "                                      test_lbl_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_dataset.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Logistic Regression model using [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html). \n",
    "\n",
    "We will split the data into 5 sets and perform five-fold cross validation. This will help generalize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/prakriti/anaconda/envs/ml_100/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/prakriti/anaconda/envs/ml_100/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/prakriti/anaconda/envs/ml_100/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/prakriti/anaconda/envs/ml_100/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91378592 0.90526579 0.90975    0.90339251 0.91905635]\n",
      "0.9102501156960354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakriti/anaconda/envs/ml_100/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instantiate\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, verbose=1,\n",
    "                           max_iter=1000, n_jobs=-1)\n",
    "\n",
    "scores = cross_val_score(model, train_dataset, train_labels, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91378592 0.90526579 0.90975    0.90339251 0.91905635]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
      "          n_jobs=-1, penalty='l2', random_state=42, solver='lbfgs',\n",
      "          tol=0.0001, verbose=1, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Model selection\n",
    "---\n",
    "\n",
    "Using cross validation we have multiple model. The following cell lets us select the best model from all the trained models using scikit-learn KFold and cross_validation_score. Later we will use LeNet to train a model for digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different parameters to understand how accuracies change.\n",
    "Understanding how decision regions change when using different regularization values.\n",
    "Remember that we use paramter C as our regularization parameter. Parameter C = 1/λ.\n",
    "Lambda (λ) controls the trade-off between allowing the model to increase it's complexity as much as it wants with trying to keep it simple. For example, if λ is very low or 0, the model will have enough power to increase it's complexity (overfit) by assigning big values to the weights for each parameter. If, in the other hand, we increase the value of λ, the model will tend to underfit, as the model will become too simple.\n",
    "Parameter C will work the other way around. For small values of C, we increase the regularization strength which will create simple models which underfit the data. For big values of C, we low the power of regularization which imples the model is allowed to increase it's complexity, and therefore, overfit the data.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "digit_acc_table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "digit_acc_table['C_parameter'] = C_param_range\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n",
    "    lr.fit(train_dataset, train_labels)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = lr.predict(test_dataset)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    digit_acc_table.iloc[j,1] = accuracy_score(test_labels,y_pred)\n",
    "    j += 1\n",
    "    \n",
    "    # Printing decision regions\n",
    "    plt.subplot(3,2,j)\n",
    "    plt.subplots_adjust(hspace = 0.4)\n",
    "    #plot_decision_regions(X = X_combined_digit_standard\n",
    "    #                  , y = Y_combined_digit\n",
    "    #                  , classifier = lr\n",
    "    #                  , test_idx = range(105,150))\n",
    "    plt.xlabel('Digit length')\n",
    "    plt.ylabel('Digit width')\n",
    "    plt.title('C = %s'%i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
