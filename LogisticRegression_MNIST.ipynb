{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Logistic Regression on [MNIST](http://yann.lecun.com/exdb/mnist/) digits\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train-images-idx3-ubyte.gz:  training set images (9912422 bytes)\n",
    "train-labels-idx1-ubyte.gz:  training set labels (28881 bytes)\n",
    "t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes)\n",
    "t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for confusion matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "# for loading MNIST\n",
    "from struct import unpack\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load downloaded dataset\n",
    "data_root = '../../books1000'\n",
    "def loadMNIST(imagefile, labelfile):\n",
    "    #img_filename = os.path.join(data_root, imagefile)\n",
    "    #lbl_filename = os.path.join(data_root, labelfile)\n",
    "    images = open(imagefile, 'rb')\n",
    "    labels = open(labelfile, 'rb')\n",
    "    \n",
    "    images.read(4)\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "    \n",
    "    labels.read(4)\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "    \n",
    "    x = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    y = np.zeros(N, dtype=np.uint8)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(rows*cols):\n",
    "            tmp_pixel = images.read(1)\n",
    "            tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "            x[i][j] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "        \n",
    "    images.close()\n",
    "    labels.close()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_filename = os.path.join(data_root, 'train-images-idx3-ubyte')\n",
    "train_lbl_filename = os.path.join(data_root, 'train-labels-idx1-ubyte')\n",
    "train_dataset, train_labels = loadMNIST(train_img_filename,\n",
    "                                        train_lbl_filename)\n",
    "\n",
    "test_img_filename = os.path.join(data_root, 't10k-images-idx3-ubyte')\n",
    "test_lbl_filename = os.path.join(data_root, 't10k-labels-idx1-ubyte')\n",
    "test_dataset, test_labels = loadMNIST(test_img_filename,\n",
    "                                      test_lbl_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_dataset.shape)\n",
    "print(test_labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
